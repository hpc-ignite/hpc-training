# 14 ‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠
## ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÅ‡∏ï‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏•‡∏á‡πÉ‡∏ô C:\hpcignite
‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢
https://drive.google.com/file/d/1c3WftbUh5r_juGTGoV_SC9PBp1fWWQpo/view?usp=sharing
## ‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Visual Studio Code ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Open Folder ‡πÑ‡∏õ‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå c:\hpcignite\webapp
### ‡πÄ‡∏õ‡∏¥‡∏î Terminal ‡πÉ‡∏ô Visual Studio ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ
‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ **Python HTTP Server** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏Æ‡∏™‡∏ï‡πå‡πÄ‡∏ß‡πá‡∏ö:

```bash
pip install flask
```

### ‡∏£‡∏±‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏≠‡∏õ
```bash
python server.py
```

## ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏§‡∏©‡∏é‡∏µ

**1. Neural Network ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?**  
Neural Network (‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°) ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡πÅ‡∏£‡∏á‡∏ö‡∏±‡∏ô‡∏î‡∏≤‡∏•‡πÉ‡∏à‡∏à‡∏≤‡∏Å‡∏™‡∏°‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ "‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó" (neurons) ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô "‡∏ã‡∏¥‡∏ô‡πÅ‡∏ô‡∏õ‡∏™‡πå" (synapses) ‡∏ã‡∏∂‡πà‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏à‡∏∞‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡πâ‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô activation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢

**2. Convolutional Neural Network (CNN)**  
CNN ‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå convolution ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏ö‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏î‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á pattern ‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡∏≠‡∏ö ‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á ‡πÅ‡∏•‡∏∞‡∏•‡∏ß‡∏î‡∏•‡∏≤‡∏¢ ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ CNN ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MNIST

**3. Distributed Data Parallel (DDP)**  
‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å Neural Network ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà DDP ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏´‡∏•‡∏≤‡∏¢ ‡πÜ GPU ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô  
- DDP ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô ‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞ GPU ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏∞‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î  
- ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ DDP ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ environment variables ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡πÄ‡∏ä‡πà‡∏ô MASTER_PORT, WORLD_SIZE ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô) ‡∏ã‡∏∂‡πà‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå `submit.sh` ÓàÄciteÓàÇturn0file3ÓàÅ

**4. ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏≠‡∏∑‡πà‡∏ô ‡πÜ**  
- **Gradient Descent ‡πÅ‡∏•‡∏∞ Backpropagation:** ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏≠‡∏á Neural Network ‡πÇ‡∏î‡∏¢‡∏Ñ‡πà‡∏≠‡∏¢ ‡πÜ ‡∏•‡∏î‡∏Ñ‡πà‡∏≤ loss ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å  
- **Dropout:** ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏Å‡∏≤‡∏£ overfitting ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏û‡∏∂‡πà‡∏á‡∏û‡∏≤‡πÄ‡∏ã‡∏•‡∏•‡πå‡πÉ‡∏î‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ  
- **Normalization:** ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏™‡πÄ‡∏Å‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡∏ã‡∏∂‡πà‡∏á‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

---

## ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠**  
‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ ‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MNIST ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠ ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ PyTorch ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö Distributed Data Parallel (DDP) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡∏ö‡∏ô‡∏´‡∏•‡∏≤‡∏¢ GPU ‡πÉ‡∏ô‡∏ã‡∏π‡πÄ‡∏õ‡∏≠‡∏£‡πå‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå

---

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MNIST**  
- ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå `dataset_download.py` ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MNIST ‡∏à‡∏≤‡∏Å‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï‡πÑ‡∏õ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î  
- ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ô‡∏µ‡πâ ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ  
- ‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÉ‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡∏°‡∏¥‡∏ô‡∏±‡∏•‡∏ß‡πà‡∏≤  
  ```
  python dataset_download.py
  ```  
- ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÅ‡∏à‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‚Äú‚úÖ MNIST dataset downloaded successfully!‚Äù ÓàÄciteÓàÇturn0file0ÓàÅ

---

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå `DDP.py`**  
- ‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ß‡∏•‡∏π‡∏ä‡∏±‡∏ô‡πÅ‡∏•‡∏∞ Fully Connected Layer  
- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `train()` ‡πÅ‡∏•‡∏∞ `test()` ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö  
- ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Distributed Data Parallel (DDP) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡∏´‡∏•‡∏≤‡∏¢ GPU ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô ‡∏ã‡∏∂‡πà‡∏á‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å  
- ‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏ß‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô ÓàÄciteÓàÇturn0file1ÓàÅ
```bash
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.optim.lr_scheduler import StepLR

import os
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from socket import gethostname

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.dropout1 = nn.Dropout(0.25)
        self.dropout2 = nn.Dropout(0.5)
        self.fc1 = nn.Linear(9216, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = F.max_pool2d(x, 2)
        x = self.dropout1(x)
        x = torch.flatten(x, 1)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.dropout2(x)
        x = self.fc2(x)
        output = F.log_softmax(x, dim=1)
        return output

def train(args, model, device, train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % args.log_interval == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))
            if args.dry_run:
                break

def test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss
            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))

def setup(rank, world_size):
    # initialize the process group
    dist.init_process_group("nccl", rank=rank, world_size=world_size)

def main():
    # Training settings
    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
    parser.add_argument('--batch-size', type=int, default=64, metavar='N',
                        help='input batch size for training (default: 64)')
    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
                        help='input batch size for testing (default: 1000)')
    parser.add_argument('--epochs', type=int, default=14, metavar='N',
                        help='number of epochs to train (default: 14)')
    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',
                        help='learning rate (default: 1.0)')
    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',
                        help='Learning rate step gamma (default: 0.7)')
    parser.add_argument('--no-cuda', action='store_true', default=False,
                        help='disables CUDA training')
    parser.add_argument('--dry-run', action='store_true', default=False,
                        help='quickly check a single pass')
    parser.add_argument('--seed', type=int, default=1, metavar='S',
                        help='random seed (default: 1)')
    parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                        help='how many batches to wait before logging training status')
    parser.add_argument('--save-model', action='store_true', default=False,
                        help='For Saving the current Model')
    args = parser.parse_args()
    use_cuda = not args.no_cuda and torch.cuda.is_available()

    torch.manual_seed(args.seed)

    train_kwargs = {'batch_size': args.batch_size}
    test_kwargs = {'batch_size': args.test_batch_size}
    if use_cuda:
        cuda_kwargs = {'num_workers': int(os.environ["SLURM_CPUS_PER_TASK"]),
                       'pin_memory': True,
                       'shuffle': True}
        train_kwargs.update(cuda_kwargs)
        test_kwargs.update(cuda_kwargs)

    transform=transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
        ])
    dataset1 = datasets.MNIST(root="./data", train=True, download=False, transform=transform)
    dataset2 = datasets.MNIST(root="./data", train=False, download=False, transform=transform)

    world_size    = int(os.environ["WORLD_SIZE"])
    rank          = int(os.environ["SLURM_PROCID"])
    gpus_per_node = int(os.environ["SLURM_GPUS_ON_NODE"])
    assert gpus_per_node == torch.cuda.device_count()
    print(f"Hello from rank {rank} of {world_size} on {gethostname()} where there are" \
          f" {gpus_per_node} allocated GPUs per node.", flush=True)

    setup(rank, world_size)
    if rank == 0: print(f"Group initialized? {dist.is_initialized()}", flush=True)

    local_rank = rank - gpus_per_node * (rank // gpus_per_node)
    torch.cuda.set_device(local_rank)
    print(f"host: {gethostname()}, rank: {rank}, local_rank: {local_rank}")

    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset1, num_replicas=world_size, rank=rank)
    train_loader = torch.utils.data.DataLoader(dataset1, batch_size=args.batch_size, sampler=train_sampler, \
                                               num_workers=int(os.environ["SLURM_CPUS_PER_TASK"]), pin_memory=True)
    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)

    model = Net().to(local_rank)
    ddp_model = DDP(model, device_ids=[local_rank])
    optimizer = optim.Adadelta(ddp_model.parameters(), lr=args.lr)

    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)
    for epoch in range(1, args.epochs + 1):
        train(args, ddp_model, local_rank, train_loader, optimizer, epoch)
        if rank == 0: test(ddp_model, local_rank, test_loader)
        scheduler.step()

    if args.save_model and rank == 0:
        torch.save(model.state_dict(), "mnist_cnn.pt")

    dist.destroy_process_group()


if __name__ == '__main__':
    main()
```

---

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡∏ã‡∏π‡πÄ‡∏õ‡∏≠‡∏£‡πå‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå**  
- ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå `submit.sh` ‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SLURM ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏ö‡∏ô‡∏ã‡∏π‡πÄ‡∏õ‡∏≠‡∏£‡πå‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå  
- ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ ‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (‡πÄ‡∏ä‡πà‡∏ô GPU ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 4 ‡∏ï‡∏±‡∏ß) ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ environment variables ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô DDP  
- ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡∏á‡∏≤‡∏ô ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÉ‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡∏°‡∏¥‡∏ô‡∏±‡∏•‡∏ß‡πà‡∏≤  
  ```
  sbatch submit.sh
  ```  
- ‡∏á‡∏≤‡∏ô‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏õ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ñ‡∏¥‡∏ß ‡∏£‡∏∞‡∏ö‡∏ö Slurm ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ 

---

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå**  
- ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏≠‡∏£‡πå‡∏°‡∏¥‡∏ô‡∏±‡∏•  
- ‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏•‡∏á‡∏Ç‡∏≠‡∏á loss ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epoch ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ  
- ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å `--save-model` ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÑ‡∏î‡πâ

---

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°**  
- ‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epoch, batch size, learning rate ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏°‡πâ‡∏Å‡∏£‡∏∞‡∏ó‡∏±‡πà‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏•‡πÄ‡∏¢‡∏≠‡∏£‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏±‡∏ö dropout) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•  
- ‡∏î‡∏π‡πÑ‡∏ü‡∏•‡πå `load_data.py` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á (transform) ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏ù‡∏∂‡∏Å 

---

## **‡∏™‡∏£‡∏∏‡∏õ:**  
‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏£‡∏π‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ LANTA Supercomputer ‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏î‡∏µ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ô‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ï‡πà‡∏≠‡πÉ‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÑ‡∏î‡πâ

---
### **üî• ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• MNIST ‡∏ö‡∏ô ONNX ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå**

‡πÉ‡∏ô‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞ **‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• PyTorch MNIST (`mnist_cnn.pt`) ‡πÄ‡∏õ‡πá‡∏ô ONNX** ‡πÅ‡∏•‡∏∞ **‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ö‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå** ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **ONNX Runtime Web (onnxruntime-web)** ‡∏ã‡∏∂‡πà‡∏á‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ **‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÅ‡∏ö‡πá‡∏Å‡πÄ‡∏≠‡∏ô‡∏î‡πå**

---

## **üìå ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ó‡∏≥**

‚úÖ **‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å PyTorch ‡πÄ‡∏õ‡πá‡∏ô ONNX**  
‚úÖ **‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô JavaScript ‡∏ú‡πà‡∏≤‡∏ô onnxruntime-web**  
‚úÖ **‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏≠‡∏õ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢**

---

# **üîπ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• PyTorch ‡πÄ‡∏õ‡πá‡∏ô ONNX**

‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡∏∑‡πà‡∏ô ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡∏à‡∏≤‡∏Å `DDP.py` ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå **ONNX** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÑ‡∏î‡πâ

### **‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô**

‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Python:

```bash
module load Mamba
conda activate /project/cb900907-hpctgn/envs/hpc-mesa
```

### **‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•**

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå **`convert_to_onnx.py`** ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
```bash
nano convert_to_onnx.py
```

```python
import torch
import onnx
from DDP import Net  # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å DDP.py

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß
model = Net()
model.load_state_dict(torch.load("mnist_cnn.pt", map_location=torch.device("cpu")))
model.eval()

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
dummy_input = torch.randn(1, 1, 28, 28)

# ‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå ONNX
onnx_file = "mnist.onnx"
torch.onnx.export(
    model, dummy_input, onnx_file,
    input_names=["input"], output_names=["output"],
    dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}}
)

print(f"‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô ONNX ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô {onnx_file}")
```

### **‚úÖ ‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•**

```bash
python convert_to_onnx.py
```

‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏±‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå `mnist.onnx` ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‚úÖ

---

# **üîπ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• ONNX ‡πÉ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå**

## **‚úÖ 2.1 ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÄ‡∏ö‡∏≤‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö**

‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ **Python HTTP Server** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏Æ‡∏™‡∏ï‡πå‡πÑ‡∏ü‡∏•‡πå `mnist.onnx` ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ß‡πá‡∏ö:

```bash
pip install flask
```

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå **`server.py`**:

```python
from flask import Flask, send_from_directory

app = Flask(__name__)

@app.route("/")
def index():
    return send_from_directory(".", "index.html")

@app.route("/<path:path>")
def serve_file(path):
    return send_from_directory(".", path)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)
```

---

## **‚úÖ 2.2 ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏≠‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå**

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå **`index.html`** ‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå:

```html
<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8">
    <title>‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏î‡πâ‡∏ß‡∏¢ MNIST (ONNX)</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js" defer></script>
</head>
<body>
    <h1>‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠</h1>
    <input type="file" id="fileInput">
    <button onclick="predict()">‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢</button>
    <p id="result"></p>

    <script>
        document.addEventListener("DOMContentLoaded", async function () {
            if (typeof ort === "undefined") {
                console.error("ONNX Runtime Web (ort) is not defined. Check if the script is correctly included.");
                return;
            }

            async function predict() {
                let fileInput = document.getElementById("fileInput");
                if (!fileInput.files.length) {
                    alert("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û!");
                    return;
                }

                let file = fileInput.files[0];
                let reader = new FileReader();
                reader.onload = async function(event) {
                    let img = new Image();
                    img.src = event.target.result;
                    img.onload = async function() {
                        let canvas = document.createElement("canvas");
                        canvas.width = 28;
                        canvas.height = 28;
                        let ctx = canvas.getContext("2d");
                        ctx.drawImage(img, 0, 0, 28, 28);

                        let imageData = ctx.getImageData(0, 0, 28, 28).data;
                        let inputTensor = new Float32Array(1 * 1 * 28 * 28);

                        for (let i = 0; i < 28 * 28; i++) {
                            inputTensor[i] = imageData[i * 4] / 255.0;
                        }

                        try {
                            let session = await ort.InferenceSession.create("mnist.onnx");
                            let results = await session.run({ "input": new ort.Tensor("float32", inputTensor, [1, 1, 28, 28]) });
                            let output = results.output.data;
                            let predictedDigit = output.indexOf(Math.max(...output));

                            document.getElementById("result").innerText = "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: " + predictedDigit;
                        } catch (error) {
                            console.error("Error running ONNX model:", error);
                        }
                    };
                };
                reader.readAsDataURL(file);
            }

            window.predict = predict;
        });
    </script>
</body>
</html>

```

---

# **üîπ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏£‡∏±‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö**

## **‚úÖ 3.1 ‡∏£‡∏±‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå**

```bash
python server.py
```

## **‚úÖ 3.2 ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏≠‡∏õ**

üìå **‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏õ‡∏ó‡∏µ‡πà** ‚Üí [http://127.0.0.1:5000/](http://127.0.0.1:5000/)  
üìå **‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• ONNX ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå**

‚úÖ ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô:

```
‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: 7
```

---

# **üîπ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á**

## ‚úÖ **‡πÇ‡∏Æ‡∏™‡∏ï‡πå‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏≠‡∏õ**

‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏Æ‡∏™‡∏ï‡πå‡πÅ‡∏≠‡∏õ‡∏ö‡∏ô **GitHub Pages, Vercel, Netlify ‡∏´‡∏£‡∏∑‡∏≠ Firebase Hosting** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÑ‡∏î‡πâ

## ‚úÖ **‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠**

‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á **UI ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏≠‡∏õ** ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **HTML + CSS** ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö **‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡πÅ‡∏ó‡πá‡∏ö‡πÄ‡∏•‡πá‡∏ï**

---

# **üîπ ‡∏™‡∏£‡∏∏‡∏õ**

‚úÖ **‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• PyTorch (`mnist_cnn.pt`) ‡πÄ‡∏õ‡πá‡∏ô ONNX (`mnist.onnx`)**  
‚úÖ **‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏≠‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• ONNX ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå**  
‚úÖ **‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ONNX Runtime Web ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÉ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå**  
‚úÖ **‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏≠‡∏õ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏Æ‡∏™‡∏ï‡πå‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÑ‡∏î‡πâ**



